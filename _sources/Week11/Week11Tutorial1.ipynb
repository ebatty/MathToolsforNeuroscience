{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOg4CG0i7eEVILjiI395QvH",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week11/Week11Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9l0lyqLvkW7"
   },
   "source": [
    "# Tutorial 1\n",
    "\n",
    "**Machine Learning III, Clustering & Classification**\n",
    "\n",
    "\n",
    "**[insert your name]**\n",
    "\n",
    "**Important reminders**: Before starting, click \"File -> Save a copy in Drive\". Produce a pdf for submission by \"File -> Print\" and then choose \"Save to PDF\".\n",
    "\n",
    "To complete this tutorial, you should have watched Video 11.1, 11.2, and 11.3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "cv9HSBNPyLV9",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Imports\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets  # interactive display\n",
    "import math\n",
    "from sklearn.cluster import KMeans"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "ZIdPVYl9TzmK",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Plotting functions\n",
    "import numpy\n",
    "from numpy.linalg import inv, eig\n",
    "from math import ceil\n",
    "from matplotlib import pyplot, ticker, get_backend, rc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
    "\n",
    "def plot_fitted_polynomials(x, y, theta_hat):\n",
    "  \"\"\" Plot polynomials of different orders\n",
    "\n",
    "  Args:\n",
    "    x (ndarray): input vector of shape (n_samples)\n",
    "    y (ndarray): vector of measurements of shape (n_samples)\n",
    "    theta_hat (dict): polynomial regression weights for different orders\n",
    "  \"\"\"\n",
    "\n",
    "  x_grid = np.linspace(x.min() - .5, x.max() + .5)\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  for order in range(0, max_order + 1):\n",
    "    X_design = make_design_matrix(x_grid, order)\n",
    "    plt.plot(x_grid, X_design @ theta_hat[order]);\n",
    "\n",
    "  plt.ylabel('y')\n",
    "  plt.xlabel('x')\n",
    "  plt.plot(x, y, 'C0.');\n",
    "  plt.legend([f'order {o}' for o in range(max_order + 1)], loc=1)\n",
    "  plt.title('polynomial fits')\n",
    "  plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "0TCUlgD2L2y7",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Helper functions\n",
    "\n",
    "def ordinary_least_squares(X, y):\n",
    "  \"\"\"Ordinary least squares estimator for linear regression.\n",
    "\n",
    "  Args:\n",
    "    x (ndarray): design matrix of shape (n_samples, n_regressors)\n",
    "    y (ndarray): vector of measurements of shape (n_samples)\n",
    "\n",
    "  Returns:\n",
    "    ndarray: estimated parameter values of shape (n_regressors)\n",
    "  \"\"\"\n",
    "  \n",
    "  # Compute theta_hat using OLS\n",
    "  theta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "  return theta_hat\n",
    "\n",
    "\n",
    "def evaluate_poly_reg(x, y, theta_hat, order):\n",
    "    \"\"\" Evaluates MSE of polynomial regression models on data\n",
    "\n",
    "    Args:\n",
    "      x (ndarray): input vector of shape (n_samples)\n",
    "      y (ndarray): vector of measurements of shape (n_samples)\n",
    "      theta_hats (dict):  fitted weights for each polynomial model (dict key is order)\n",
    "      max_order (scalar): max order of polynomial fit\n",
    "\n",
    "    Returns\n",
    "      (ndarray): mean squared error for each order, shape (max_order)\n",
    "    \"\"\"\n",
    "\n",
    "    X_design = make_design_matrix(x, order)\n",
    "\n",
    "    y_hat = np.dot(X_design, theta_hats[order])\n",
    "\n",
    "    residuals = y - y_hat\n",
    "\n",
    "    mse = np.mean(residuals ** 2)\n",
    "\n",
    "    return mse\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqrRM9GtNp0B"
   },
   "source": [
    "# Exercise 1: Exploring details of K-Means\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5LZgMpqdPQs"
   },
   "source": [
    "## A) Wrong clustering\n",
    "\n",
    "Below I have generated some data and clustered with K-Means. The resulting cluster labels are shown by color. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute to visualize \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xcq1dAgnQAPM",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute to visualize \n",
    "# Create data\n",
    "np.random.seed(0)\n",
    "\n",
    "data1 = np.random.multivariate_normal((60, 1), [[50, 0], [0, .1]], size=(100,))\n",
    "data2 = np.random.multivariate_normal((50, 5), [[50, 0], [0, .1]], size=(150,))\n",
    "\n",
    "data = np.concatenate((data1, data2), axis=0)\n",
    "\n",
    "clustering = KMeans(n_clusters = 2)\n",
    "clustering.fit(data)\n",
    "labels = clustering.labels_\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for k in range(2):\n",
    "    ax.plot(data[labels==k, 0], data[labels==k, 1], 'o', label='Cluster '+str(k))\n",
    "    ax.set(aspect='auto')\n",
    "ax.legend();"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ0cS-cPdcOR"
   },
   "source": [
    "i) Why has the clustering not worked?  Hints: the plot above should tell you everything you need to know, think about the cluster assignment step with this data\n",
    "\n",
    "ii) What could we do to get the clustering to work properly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15F7KjCoeNNA"
   },
   "source": [
    "### Answer\n",
    "\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "i) <br>\n",
    "ii) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psP5CgG5ebzw"
   },
   "source": [
    "## B) Objective function of K-Means\n",
    "\n",
    "Is the graph below of the value of the objective function J over the iteration step of the K-Means clustering possible with a correctly implemented K-Means algorithm? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute to visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WmyHO99ye012",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute to visualize\n",
    "x = np.arange(0, 50)\n",
    "J = 50-x-2*np.sin(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, J)\n",
    "ax.set(xlabel='Iteration of K-means clustering', ylabel = 'J');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biIboSaIekBP"
   },
   "source": [
    "### Answer\n",
    "\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIlSX0HUQBcc"
   },
   "source": [
    "# (Optional) Exercise: Implement K-Means yourself\n",
    "\n",
    "Later in this tutorial we will use sklearn to compute K Means. This isn't too difficult an algorithm to code yourself though and doing so can solidify your understanding. Use the pseudocode in video 11.3 as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPf4uor5QFRu"
   },
   "source": [
    "# your code here"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxMJzRWVgCJH"
   },
   "source": [
    "# The Data\n",
    "\n",
    "We will be looking at real RNAseq data to cluster cells into different cell types. Specifically, we will be using a dataset of Peripheral Blood Mononuclear Cells (PBMC) available from 10X Genomics. \n",
    "\n",
    "In RNA-seq, we are measuring the gene expression for each cell for a large number of cells. When genes are expressed, they're transcribed into mRNA, which is then translated into proteins. In RNA-seq, we sequence how many mRNA molecules are present that correspond to each gene we're interested in. \n",
    "\n",
    "Execute the next cell to download the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute to get data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E3KLln7RZaMy",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute to get data\n",
    "import requests\n",
    "import urllib.request\n",
    "import io\n",
    "import tempfile\n",
    "import tarfile\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "respurl = 'https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz'\n",
    "with requests.get(respurl,stream = True) as File:\n",
    "    # stream = true is required by the iter_content below\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "        with open(tmp_file.name,'wb') as fd:\n",
    "            for chunk in File.iter_content(chunk_size=128):\n",
    "                fd.write(chunk)\n",
    "\n",
    "with tarfile.open(tmp_file.name,\"r:gz\") as tf:\n",
    "  for tarinfo_member in tf:\n",
    "\n",
    "    if os.path.splitext(tarinfo_member.name)[1] == \".mtx\":\n",
    "        mtx_file = tf.extractfile(tarinfo_member)\n",
    "        content = mtx_file.read()\n",
    "        data = scipy.io.mmread(io.BytesIO(content))\n",
    "\n",
    "data = np.array(data.todense()).T              "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhWfstnIh8Ep"
   },
   "source": [
    "What we have downloaded is a **unique molecular identified (UMI) count matrix** (stored as `data`). \n",
    "\n",
    "The rows of this matrix are the cells (2700) and the columns are the different genes we are examining (32738).\n",
    "\n",
    "Each value in this matrix represents the number of molecules for the corresponding gene that are detected in the corresponding cell. I.e. if the value in the 5th row and 10th column is 3, there were 3 molecules of gene 10 found in cell 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfq5n_-Gk6WQ"
   },
   "source": [
    "# Step 1: Remove non-cells\n",
    "\n",
    "First, we remove any rows that seem to correspond to things that aren't really cells. We may have low-quality cells, empty droplets or errors where more than one cell have been sequenced together (a row corresponds to 2 or more cells). Really you would use a variety of metrics to ascertain the quality of each cell but we can use a fairly simple one for now - the number of unique genes detected in each cell. Low-quality cells or droplets would have very small number of genes, while double or tripled cells would have a lot. \n",
    "\n",
    "We can get the number of unique genes per cell by finding the number of non-zero values in the matrix in each row:\n",
    " \n",
    " `np.sum(data > 0, axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lVrISFEJjuq2"
   },
   "source": [
    "n_genes = np.sum(data > 0, axis=1) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(n_genes, 100, color='k');\n",
    "ax.set(xlabel = 'Number of unique genes', ylabel = 'Number of cells');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r8HNhbVojPd"
   },
   "source": [
    "Let's remove cells that are at the two extremes of this distribution (fewer or more unique genes than most of the cells). We will remove cells that not in the middle 5 - 95th percentile range. Note that this is similar to building a confidence interval from bootstrapping!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zUUMRiy7ncDR"
   },
   "source": [
    "lower_threshold = np.percentile(n_genes, 5)\n",
    "upper_threshold = np.percentile(n_genes, 95)\n",
    "\n",
    "keep_cells = (n_genes > lower_threshold) & (n_genes < upper_threshold)\n",
    "\n",
    "quality_cell_data = data[keep_cells]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKqx7OvITrZy"
   },
   "source": [
    "# Step 2: Remove uninformative genes\n",
    "\n",
    "In our data, some genes are not present in any cell. These genes are completely uninformative so we will remove them. Seurat, an R package for RNA-seq analysis, takes this further and only keeps the top 2000 most variable genes (the genes that vary the most in terms of how much they are present across cells) but we won't tackle this."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jKK6s4CkUAYc"
   },
   "source": [
    "quality_gene_data = quality_cell_data[:, np.where(np.sum(quality_cell_data, axis=0)>0)[0]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkFHLWBBalXF"
   },
   "source": [
    "We next normalize the feature expression labels for each cell by the total expression. I am using what (I believe) Seurat suggests below. Honestly, I'm not completely sure why they choose to do it this way so we'll just do it and move on..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d9FPedGwQ8Lj"
   },
   "source": [
    "quality_gene_data = np.log(10000*(quality_gene_data/np.sum(quality_gene_data, axis=1)[:, None])+1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYQYVVIBprMj"
   },
   "source": [
    "# Step 3: Standardize the data\n",
    "\n",
    "Let's standardize our data before continuing. This is often a preprocessing step performed before further modeling. Standardizing the data means making each feature have mean 0 and standard deviation 1 (resembling a standard normal distribution). \n",
    "\n",
    "Side note: this is slightly different than whitening the data where we are also making each feature uncorrelated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chinxyjFrUTY"
   },
   "source": [
    "## Exercise 2: Standardize the data\n",
    "\n",
    "Standardize the `quality_gene_data` array so that each feature has mean 0 and standard deviation 1. \n",
    "\n",
    "\n",
    "To figure out how to make the standard deviation 1, it may be helpful to know that:\n",
    "\n",
    "$$ std(a\\bar{x}) = a std(\\bar{x}) $$\n",
    "\n",
    "where $a$ is a constant and $\\bar{x}$ is a vector of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUGf86GSquse"
   },
   "source": [
    "### Answer\n",
    "Code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dyuwTCHAp0SO"
   },
   "source": [
    "# your code here (remember to use quality_gene_data)\n",
    "mean_centered_data = ...\n",
    "standardized_data = ..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqVeNRCrn0wJ"
   },
   "source": [
    "You can check you've done this correctly by looking at the mean and standard deviation of each gene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpgDI5-dr-xs"
   },
   "source": [
    "# Step 4: PCA\n",
    "\n",
    "Before we cluster our data into different cell types (groups of similar cells), we want to perform dimensionality reduction. Clustering doesn't work very well in very high dimensional space and this space is extremely high dimensional as we have 32738 genes. In general, problems arising with high dimensional data are referred to as the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). Specifically for clustering, distance measures in high dimensional spaces become somewhat meaningless so it is difficult to assess which data points are close together.\n",
    "\n",
    "Luckily, we know all about dimensionality reduction and can use PCA to transform our data into a lower dimensional space. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U2K6Is1FgXC"
   },
   "source": [
    "## Exercise 3: Get low-d representation\n",
    "\n",
    "Use `PCA` from sklearn (imported below) to do this. First, fit PCA with all components and look at the plot of explained variance vs component number to choose a reasonable number of components to keep for clustering (you will want to use the `explained_variance_ratio_` attribute of the pca class). Then transform the data into this low-D PCA space.\n",
    "\n",
    "This will take a few minutes since we have so many genes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kguw3E8oq0lZ"
   },
   "source": [
    "### Answer\n",
    "Code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_BLOhfdOBde2"
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA on standardized_data\n",
    "\n",
    "\n",
    "# Plot explained variance vs component number\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4PWRyiovFCb4"
   },
   "source": [
    "# Transform data into low d space\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLV802VgsBYg"
   },
   "source": [
    "# Step 5: Clustering\n",
    "\n",
    "We're finally ready to cluster our cell types! We will use the [`KMeans` class from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). When we call the `fit` method of this class, it fits the clusters according to the number you have prechosen. It fits `n_init` times where the default is 10 and takes the best run.\n",
    "\n",
    "We want to first look at the objective function value for different numbers of clusters so we can see whether there is an elbow (an obvious choice for number of clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpQUE07gF_VD"
   },
   "source": [
    "## Exercise 4: Cluster the data\n",
    "\n",
    "Complete the code below to run k means with varying numbers of clusters and record the objective function value. \n",
    "\n",
    "Hint: the objective function is computed for you and will be one of the attributes of the model - look at the attributes section of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFOpNI-VrYmz"
   },
   "source": [
    "### Answer\n",
    "Code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iCEpsmKZrinp"
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "js = np.zeros((30,)) # we will store our objective function values here\n",
    "\n",
    "# Loop through 1 through 30 clusters\n",
    "for k in range(1, 30):\n",
    "    \n",
    "    # Fit K Means model with k clusters\n",
    "    ...\n",
    "\n",
    "\n",
    "    js[k] = ... # get objective function value for this k\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, 30), js[1:], 'ok')\n",
    "ax.set(xlabel = 'k', ylabel = 'J');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icZXE5z_GjtV"
   },
   "source": [
    "Choose a reasonable number of clusters based on the above plot and rerun with that number of clusters. This tells us approximately how many cell types are present in our data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB60H0P5rcAd"
   },
   "source": [
    "### Answer\n",
    "Code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rTZDx3udK5Jv"
   },
   "source": [
    "chosen_k = ... # put the k value you've chosen here (we'll use it later)\n",
    "\n",
    "# Fit k means model with chosen_k clusters\n",
    "model = ...\n",
    "\n",
    "# Output cluster labels of each data point\n",
    "labels = model.labels_"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW3FziehGxT0"
   },
   "source": [
    "\n",
    "# Step 5: Visualizing clusters\n",
    "\n",
    "We want to take a look at our clusters! We have kept higher than three PCs though so it's difficult to visualize even in our low-D PC space. We will use tSNE to visualize our data in 2D space. tSNE is a nonlinear dimensionality reduction technique often used to visualize high d data in low d space. It is also a bit controversial in the scientific community. I'm not that caught up on the tSNE debate (and rarely use it) but the gist is that tSNE plots are often misinterpreted and depend on a hyperparameter that you set - check out this[ article ](https:////distill.pub/2016/misread-tsne/) and [this one](https://distill.pub/2016/misread-tsne/) for more details.\n",
    "Overall, I would say that **tSNE should be used for visualization, not in preprocessing like PCA, and should be intepreted extremely carefully**\n",
    "\n",
    "Another thing to keep in mind with tSNE is that, like clustering, it's not great at dealing with really high D space. This is a little confusing since that is the whole point of tsne - to convert high d to low d. It's pretty good at converting 10-d space for example to 2-d space but not at converting 32738-d space to 2-d space. Because of this, even when we use tSNE to visualize, we often perform PCA first. So a common pipeline is 1) Perform PCA and cast to ~20-d space, 2) Perform tSNE to cast to 2 or 3-d space. Here, we will use our pca data as the input for tSNE.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "shOqzqRfFZpS"
   },
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Transform PCA data into 2D space with tsne\n",
    "tsne = TSNE(n_components = 2, random_state = 1)\n",
    "tsne_data = tsne.fit_transform(lowd_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6pZJW_xNKNzi"
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "for k in range(chosen_k):\n",
    "    ax.plot(tsne_data[labels==k, 0], tsne_data[labels==k, 1], 'o', label = 'Cluster ' + str(k))\n",
    "\n",
    "ax.legend();\n",
    "ax.set(title = 'Clustered cell types from RNA-seq data', xlabel = 'tSNE Dimension 1', ylabel = 'tSNE Dimension 2');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3CW2P4_oTFM"
   },
   "source": [
    "Do these clusters look reasonable to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZciUk8_apfq8"
   },
   "source": [
    "\n",
    "Now we could do lots more interesting analyses about what genes are most characteristic of each cell type, what cell types our clusters might actually be, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7gHBwYPpCfr"
   },
   "source": [
    "# More info\n",
    "\n",
    "[Click for an overview of the Seurat R package for analyzing RNA-seq data which this pipeline was based on](\n",
    "https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html)\n",
    "\n",
    "[Click for the git repo for the Harvard Chan Bioinformatics Core training on RNA-seq data](\n",
    "https://github.com/hbctraining/scRNA-seq/tree/master/schedule)\n",
    "\n",
    "[Click for a recent paper about clustering cell types from RNA-seq data](https://www.nature.com/articles/s41598-020-66848-3)"
   ]
  }
 ]
}